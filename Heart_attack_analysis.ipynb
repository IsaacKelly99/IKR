{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart_attack_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Vps9W8tyVC"
      },
      "source": [
        "# Hearth attack prediction\n",
        "Using the heart attack analysis prediction dataset i will try to predict the probability of someone getting a heart attack based on the given data.\n",
        "\n",
        "Making use of the next tools: \n",
        "* KNN classifier and data pipelines to fit and predict the model.\n",
        "* Scaling to scale the data and obtain a higher and precission.\n",
        "* train_test_split to split the data.\n",
        "* classification report to obtain the performance of the model \n",
        "and\n",
        "* GridsearchCV to choose the best hyperparameters for the KNN classifier.\n",
        "\n",
        "link to the original kaggle dataset -> https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset?select=heart.csv\n",
        "\n",
        "Sckit-learn documentation: Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011. https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfLSPlRWiXcW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "ZPClalvBuBQO",
        "outputId": "b838e14f-f891-46c4-ae59-ca01ab9b7a4f"
      },
      "source": [
        "# Dataset import\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/data_for_colab/heart.csv\")\n",
        "# its important to look for missing values in the data\n",
        "def na_status(df):\n",
        "  total = df.isnull().sum().sort_values(ascending=False)\n",
        "  percent_1 = df.isnull().sum()/df.isnull().count()*100\n",
        "  percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
        "  missing_data = pd.concat([total, percent_2], axis=1, keys=['Total NaN', 'NaN %'])\n",
        "  print(missing_data.head(10))\n",
        "na_status(df)\n",
        "#First glimpse into the dataframe\n",
        "df.info()\n",
        "df.describe()\n",
        "#This dataframe does not contain missing values\n",
        "# All of its columns are numerical, therefore an encoder wont be needed this time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          Total NaN  NaN %\n",
            "output            0    0.0\n",
            "thall             0    0.0\n",
            "caa               0    0.0\n",
            "slp               0    0.0\n",
            "oldpeak           0    0.0\n",
            "exng              0    0.0\n",
            "thalachh          0    0.0\n",
            "restecg           0    0.0\n",
            "fbs               0    0.0\n",
            "chol              0    0.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trtbps    303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalachh  303 non-null    int64  \n",
            " 8   exng      303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slp       303 non-null    int64  \n",
            " 11  caa       303 non-null    int64  \n",
            " 12  thall     303 non-null    int64  \n",
            " 13  output    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>54.366337</td>\n",
              "      <td>0.683168</td>\n",
              "      <td>0.966997</td>\n",
              "      <td>131.623762</td>\n",
              "      <td>246.264026</td>\n",
              "      <td>0.148515</td>\n",
              "      <td>0.528053</td>\n",
              "      <td>149.646865</td>\n",
              "      <td>0.326733</td>\n",
              "      <td>1.039604</td>\n",
              "      <td>1.399340</td>\n",
              "      <td>0.729373</td>\n",
              "      <td>2.313531</td>\n",
              "      <td>0.544554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.082101</td>\n",
              "      <td>0.466011</td>\n",
              "      <td>1.032052</td>\n",
              "      <td>17.538143</td>\n",
              "      <td>51.830751</td>\n",
              "      <td>0.356198</td>\n",
              "      <td>0.525860</td>\n",
              "      <td>22.905161</td>\n",
              "      <td>0.469794</td>\n",
              "      <td>1.161075</td>\n",
              "      <td>0.616226</td>\n",
              "      <td>1.022606</td>\n",
              "      <td>0.612277</td>\n",
              "      <td>0.498835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>211.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>133.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>274.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>564.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age         sex          cp  ...         caa       thall      output\n",
              "count  303.000000  303.000000  303.000000  ...  303.000000  303.000000  303.000000\n",
              "mean    54.366337    0.683168    0.966997  ...    0.729373    2.313531    0.544554\n",
              "std      9.082101    0.466011    1.032052  ...    1.022606    0.612277    0.498835\n",
              "min     29.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     47.500000    0.000000    0.000000  ...    0.000000    2.000000    0.000000\n",
              "50%     55.000000    1.000000    1.000000  ...    0.000000    2.000000    1.000000\n",
              "75%     61.000000    1.000000    2.000000  ...    1.000000    3.000000    1.000000\n",
              "max     77.000000    1.000000    3.000000  ...    4.000000    3.000000    1.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YongKgff0nwp",
        "outputId": "44bf6cca-6e1b-4ec7-e360-c57743db425f"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV, GridSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#The classifier and scaler that will be passed on to the pipeline\n",
        "knn = KNeighborsClassifier()\n",
        "scaler=StandardScaler()\n",
        "\n",
        "# The parameters for the model\n",
        "leaf_size = list(range(1,50))\n",
        "p=[1,2]\n",
        "param_grid = {'knn__n_neighbors': np.arange(1, 50),\n",
        "             \"knn__leaf_size\":leaf_size,\n",
        "               \"knn__p\":p}\n",
        "\n",
        "# The target column will be \"output\", lets define the features and the target\n",
        "X = df.drop(\"output\", axis=1).values\n",
        "y = df[\"output\"].values\n",
        "\n",
        "#Now lets define the pipeline and its steps\n",
        "steps = [(\"scaler\",scaler),  (\"knn\", knn)]\n",
        "\n",
        "# The steps should be called inside of the pipeline\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "# The dataframe will need to be separated into training and testing variables\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
        "cv = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
        "\n",
        "#Lets fit the model into the data\n",
        "knn = pipeline.fit(X_train, y_train)\n",
        "knn_hyper = cv.fit(X_train, y_train)\n",
        "#Now the predictions\n",
        "y_pred = knn.predict(X_test)\n",
        "y_pred = knn_hyper.predict(X_test)\n",
        "\n",
        "#Lets print the score for both models\n",
        "print(\"Knn model with Hyperparameter tunning\")\n",
        "print(knn_hyper.best_params_)\n",
        "print(knn_hyper.score(X_test,y_test))\n",
        "print(\"\\n\")\n",
        "print(\"knn basic model\")\n",
        "print(knn.score(X_test,y_test))\n",
        "print(\"\\n\",\n",
        "      \"Classification report\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "# We can see that the basic model, without the Hyper parameter tuning achieved a higher score than the other one."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Knn model with Hyperparameter tunning\n",
            "{'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n",
            "0.8360655737704918\n",
            "\n",
            "\n",
            "knn basic model\n",
            "0.9016393442622951\n",
            "\n",
            " Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83        29\n",
            "           1       0.84      0.84      0.84        32\n",
            "\n",
            "    accuracy                           0.84        61\n",
            "   macro avg       0.84      0.84      0.84        61\n",
            "weighted avg       0.84      0.84      0.84        61\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "mEDYYvnxD-fx",
        "outputId": "8d5dba24-d290-4204-903a-1cbb11bd4f71"
      },
      "source": [
        "# Importing the other 3 models to be tested\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Defining a list with such models, including the model name and its hyperparameters\n",
        "list_of_models = {    \n",
        "    'svm': {'model': svm.SVC(gamma='auto'),'params' : {'C': [1,10,20],'kernel': ['rbf','linear']}},\n",
        "    'random_forest': {'model': RandomForestClassifier(),'params' : {'n_estimators': [1,5,10]}}\n",
        "}\n",
        "#Creating the scores variable that later will be converted to a dataframe\n",
        "scores = []\n",
        "for model_name, mp in list_of_models.items():\n",
        "    clf =  GridSearchCV(mp['model'], mp['params'], cv=3, return_train_score=False)\n",
        "    clf.fit(X_train, y_train)\n",
        "    scores.append({\n",
        "        'model': model_name,\n",
        "        'best_score': clf.best_score_,\n",
        "        'best_params': clf.best_params_\n",
        "    })\n",
        "    \n",
        "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>best_score</th>\n",
              "      <th>best_params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>svm</td>\n",
              "      <td>0.793673</td>\n",
              "      <td>{'C': 20, 'kernel': 'linear'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>random_forest</td>\n",
              "      <td>0.781121</td>\n",
              "      <td>{'n_estimators': 5}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           model  best_score                    best_params\n",
              "0            svm    0.793673  {'C': 20, 'kernel': 'linear'}\n",
              "1  random_forest    0.781121            {'n_estimators': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUHMgduWHtbY"
      },
      "source": [
        "`The KNN classifier, using its default settings was the best performing classifier`"
      ]
    }
  ]
}
