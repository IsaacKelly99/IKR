{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wikipedia_recomendations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1irTjaBkXr320BXsZdDM1eRLnoQUBYPGW",
      "authorship_tag": "ABX9TyNr0MlnQFYxXkvXbKAk5NCP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsaacKelly99/IKR/blob/master/wikipedia_recomendations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tms16pG9r6Ti"
      },
      "source": [
        "#Wikipedia recommender \n",
        "## ML unsupervised learning\n",
        "\n",
        "I created a wikipedia recommender program using NMF from the sckit learn-  decomposition module\n",
        "\n",
        "Other tools used:\n",
        "- TfidfVectorizer, to create a tfidf from the dataframe\n",
        "- normalize\n",
        "- TruncatedSVD\n",
        "- make_pipeline\n",
        "- Kmeans, for clustering\n",
        "- pandas: read_csv, loc, dot, etc.\n",
        "- numpy\n",
        "\n",
        "The wikipedia dataset: https://www.lateral.io/resources-blog/the-unknown-perils-of-mining-wikipedia\n",
        "\n",
        "This excercise was part of the 'Unsupervised learning in python' course from datacamp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdCSMNp0_zqK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqpkvxkBBry6"
      },
      "source": [
        "wiki = pd.read_csv(\"/content/drive/MyDrive/data_for_colab/wikipedia-vectors.csv\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "d44U9yQSBwLM",
        "outputId": "e9d3b9a1-988b-418e-81d2-4c6e5b07e5b7"
      },
      "source": [
        "wiki.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>HTTP 404</th>\n",
              "      <th>Alexa Internet</th>\n",
              "      <th>Internet Explorer</th>\n",
              "      <th>HTTP cookie</th>\n",
              "      <th>Google Search</th>\n",
              "      <th>Tumblr</th>\n",
              "      <th>Hypertext Transfer Protocol</th>\n",
              "      <th>Social search</th>\n",
              "      <th>Firefox</th>\n",
              "      <th>LinkedIn</th>\n",
              "      <th>Global warming</th>\n",
              "      <th>Nationally Appropriate Mitigation Action</th>\n",
              "      <th>Nigel Lawson</th>\n",
              "      <th>Connie Hedegaard</th>\n",
              "      <th>Climate change</th>\n",
              "      <th>Kyoto Protocol</th>\n",
              "      <th>350.org</th>\n",
              "      <th>Greenhouse gas emissions by the United States</th>\n",
              "      <th>2010 United Nations Climate Change Conference</th>\n",
              "      <th>2007 United Nations Climate Change Conference</th>\n",
              "      <th>Angelina Jolie</th>\n",
              "      <th>Michael Fassbender</th>\n",
              "      <th>Denzel Washington</th>\n",
              "      <th>Catherine Zeta-Jones</th>\n",
              "      <th>Jessica Biel</th>\n",
              "      <th>Russell Crowe</th>\n",
              "      <th>Mila Kunis</th>\n",
              "      <th>Dakota Fanning</th>\n",
              "      <th>Anne Hathaway</th>\n",
              "      <th>Jennifer Aniston</th>\n",
              "      <th>France national football team</th>\n",
              "      <th>Cristiano Ronaldo</th>\n",
              "      <th>Arsenal F.C.</th>\n",
              "      <th>Radamel Falcao</th>\n",
              "      <th>Zlatan Ibrahimović</th>\n",
              "      <th>Colombia national football team</th>\n",
              "      <th>2014 FIFA World Cup qualification</th>\n",
              "      <th>Football</th>\n",
              "      <th>Neymar</th>\n",
              "      <th>Franck Ribéry</th>\n",
              "      <th>Tonsillitis</th>\n",
              "      <th>Hepatitis B</th>\n",
              "      <th>Doxycycline</th>\n",
              "      <th>Leukemia</th>\n",
              "      <th>Gout</th>\n",
              "      <th>Hepatitis C</th>\n",
              "      <th>Prednisone</th>\n",
              "      <th>Fever</th>\n",
              "      <th>Gabapentin</th>\n",
              "      <th>Lymphoma</th>\n",
              "      <th>Chad Kroeger</th>\n",
              "      <th>Nate Ruess</th>\n",
              "      <th>The Wanted</th>\n",
              "      <th>Stevie Nicks</th>\n",
              "      <th>Arctic Monkeys</th>\n",
              "      <th>Black Sabbath</th>\n",
              "      <th>Skrillex</th>\n",
              "      <th>Red Hot Chili Peppers</th>\n",
              "      <th>Sepsis</th>\n",
              "      <th>Adam Levine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.049502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00611</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029607</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007054</td>\n",
              "      <td>0.006915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020774</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005646</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029339</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  HTTP 404  ...   Sepsis  Adam Levine\n",
              "0           0       0.0  ...  0.00000          0.0\n",
              "1           1       0.0  ...  0.00611          0.0\n",
              "2           2       0.0  ...  0.00000          0.0\n",
              "3           3       0.0  ...  0.00000          0.0\n",
              "4           4       0.0  ...  0.00000          0.0\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Vl8FIfDY8s",
        "outputId": "9af81d83-3410-4726-c832-c033487df976"
      },
      "source": [
        "# Import TfidfVectorizer from sklearn extraction tet\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Create a TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "# Apply fit_transform to document to turn wiki into a tfidf, the new variable is csr_mat\n",
        "csr_mat = tfidf.fit_transform(wiki)\n",
        "# Print result of toarray() method\n",
        "print(csr_mat.toarray())\n",
        "# Get the words, stored as feature names in the tfidf\n",
        "words = tfidf.get_feature_names()\n",
        "# get the name of the columns as a np array\n",
        "titles = np.array(wiki.columns)\n",
        "articles = csr_mat\n",
        "# Print words\n",
        "print(words)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "['2007', '2010', '2014', '350', '404', 'action', 'adam', 'alexa', 'angelina', 'aniston', 'anne', 'appropriate', 'arctic', 'arsenal', 'biel', 'black', 'by', 'catherine', 'chad', 'change', 'chili', 'climate', 'colombia', 'conference', 'connie', 'cookie', 'cristiano', 'crowe', 'cup', 'dakota', 'denzel', 'doxycycline', 'emissions', 'explorer', 'falcao', 'fanning', 'fassbender', 'fever', 'fifa', 'firefox', 'football', 'france', 'franck', 'gabapentin', 'gas', 'global', 'google', 'gout', 'greenhouse', 'hathaway', 'hedegaard', 'hepatitis', 'hot', 'http', 'hypertext', 'ibrahimović', 'internet', 'jennifer', 'jessica', 'jolie', 'jones', 'kroeger', 'kunis', 'kyoto', 'lawson', 'leukemia', 'levine', 'linkedin', 'lymphoma', 'michael', 'mila', 'mitigation', 'monkeys', 'nate', 'national', 'nationally', 'nations', 'neymar', 'nicks', 'nigel', 'org', 'peppers', 'prednisone', 'protocol', 'qualification', 'radamel', 'red', 'ribéry', 'ronaldo', 'ruess', 'russell', 'sabbath', 'search', 'sepsis', 'skrillex', 'social', 'states', 'stevie', 'team', 'the', 'tonsillitis', 'transfer', 'tumblr', 'united', 'unnamed', 'wanted', 'warming', 'washington', 'world', 'zeta', 'zlatan']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od1goMN1CBsT",
        "outputId": "12734e74-e7fe-4856-c384-2c76e50af920"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "# Create a TruncatedSVD instance called svd\n",
        "svd = TruncatedSVD(n_components=50)\n",
        "# Create a KMeans instance called kmeans, with 6 clusters\n",
        "kmeans = KMeans(n_clusters=6)\n",
        "# Create a pipeline named pipeline\n",
        "pipeline = make_pipeline(svd, kmeans)\n",
        "# fit it to tdif articles\n",
        "pipeline.fit(articles)\n",
        "# Calculate/predict the cluster labels as labels\n",
        "labels = pipeline.predict(articles)\n",
        "# Create a DataFrame aligning labels and titles as df\n",
        "df = pd.DataFrame({'label': labels, 'article': titles})\n",
        "# Display df sorted by cluster label, using sort_values\n",
        "print(df.sort_values(\"label\"))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    label                                        article\n",
            "59      0                                         Sepsis\n",
            "49      1                                     Gabapentin\n",
            "0       2                                     Unnamed: 0\n",
            "32      2                              Cristiano Ronaldo\n",
            "33      2                                   Arsenal F.C.\n",
            "..    ...                                            ...\n",
            "15      4                                 Climate change\n",
            "20      4  2007 United Nations Climate Change Conference\n",
            "36      5                Colombia national football team\n",
            "31      5                  France national football team\n",
            "38      5                                       Football\n",
            "\n",
            "[61 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztO8fz3lJX9_"
      },
      "source": [
        "We can see that some football teams have similar labels, sucho as the colombian, and french national team (5), the arsenal and Cristiano ronaldo have the same labels as well (2), and the climate related articles such as the ONU conference and the Climate change article are labeled as 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvDgIJkdG_U9",
        "outputId": "22b88b76-4e22-4ec5-c27e-d4c368180912"
      },
      "source": [
        "# Import NMF\n",
        "from sklearn.decomposition import NMF\n",
        "#number of components for the Nmf \n",
        "fnmf= 6 \n",
        "# Create an NMF instance with 6 components, assigned to model\n",
        "model = NMF(n_components= fnmf)\n",
        "# Fit the model to articles\n",
        "model.fit(articles)\n",
        "# Transform the articles\n",
        "nmf_features = model.transform(articles)\n",
        "# Print the NMF features\n",
        "print(nmf_features.round(2))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.8 ]\n",
            " [0.   0.   0.   0.59 0.   0.  ]\n",
            " [0.   0.   0.   0.59 0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.8 ]\n",
            " [0.   0.   0.   0.   0.68 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.68 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.63 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.15 0.   0.   0.   0.   0.  ]\n",
            " [0.74 0.   0.   0.   0.   0.  ]\n",
            " [0.74 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.73 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.73 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.62 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.84 0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.84 0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.03 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6_YxsFQHEqM",
        "outputId": "f5e9fcc7-2782-4096-ab88-66a5a9262db6"
      },
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "# Create a pandas DataFrame: df\n",
        "df = pd.DataFrame(nmf_features, index=titles)\n",
        "# Print the row for 'Google Search'\n",
        "print(df.loc[\"Google Search\"])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.000000\n",
            "1    0.000000\n",
            "2    0.000000\n",
            "3    0.000000\n",
            "4    0.682035\n",
            "5    0.000000\n",
            "Name: Google Search, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMqKjpiNHJGb",
        "outputId": "b9dcfc83-1296-4a76-c675-407b5fae3fda"
      },
      "source": [
        "# Create a DataFrame,called components_df, using the words as columns\n",
        "components_df = pd.DataFrame(model.components_,columns=words)\n",
        "# Print the shape of the DataFrame\n",
        "print(components_df.shape)\n",
        "# Select row 3: component\n",
        "component = components_df.iloc[3]\n",
        "# Print result of nlargest\n",
        "print(component.nlargest())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 111)\n",
            "internet       1.138759e+00\n",
            "alexa          6.266867e-01\n",
            "explorer       6.266867e-01\n",
            "fever          3.294263e-10\n",
            "tonsillitis    2.719892e-10\n",
            "Name: 3, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOOe0Le8HP-r"
      },
      "source": [
        "# import normalize to use on the data\n",
        "from sklearn.preprocessing import normalize\n",
        "# Normalizing the NMF features\n",
        "norm_features = normalize(nmf_features)\n",
        "# Create a DataFrame with the normalized features\n",
        "df = pd.DataFrame(norm_features, index=titles)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "X1TTmSCAIuTy",
        "outputId": "fb53c53a-8ce9-4b18-e829-3b7e0fbf2837"
      },
      "source": [
        "# a look on the dataframe, this is how our normalized articles look like\n",
        "df.head(3)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.228529e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HTTP 404</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alexa Internet</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0             1    2    3    4    5\n",
              "Unnamed: 0      0.0  1.228529e-09  0.0  0.0  1.0  0.0\n",
              "HTTP 404        0.0  0.000000e+00  0.0  0.0  0.0  1.0\n",
              "Alexa Internet  0.0  0.000000e+00  0.0  1.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Oj-7dNHTNU",
        "outputId": "a8a5d9b3-ca98-41e2-d8d9-4e8067dd1625"
      },
      "source": [
        "# Select the row corresponding to 'X': article\n",
        "article = df.loc['Google Search']\n",
        "# Compute the dot products, using df.dot, and assing them to similarities\n",
        "similarities = df.dot(article)\n",
        "# Display the dit products with the largest cosine similarity\n",
        "print(similarities.nlargest())\n",
        "# We can see that the largest values are related articles"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unnamed: 0                     1.0\n",
            "Google Search                  1.0\n",
            "Tumblr                         1.0\n",
            "Hypertext Transfer Protocol    1.0\n",
            "Social search                  1.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQTur3_hHrya"
      },
      "source": [
        "We can see that the related articles are assigned largest values, this is how a basic search engine works, based on our prefferences it recomends videos, articles, or posts based on its similarity to the ones we've previously seen or liked."
      ]
    }
  ]
}